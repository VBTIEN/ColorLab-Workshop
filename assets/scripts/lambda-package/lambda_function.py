import json
import boto3
import base64
from urllib.parse import unquote_plus
import uuid
from datetime import datetime

# Initialize AWS clients
rekognition = boto3.client('rekognition')
s3 = boto3.client('s3')
bedrock = boto3.client('bedrock-runtime')

def lambda_handler(event, context):
    """
    Lambda function ƒë·ªÉ ph√¢n t√≠ch ·∫£nh v·ªõi Amazon Rekognition v√† Bedrock
    """
    
    # Add CORS headers
    headers = {
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Headers': 'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token',
        'Access-Control-Allow-Methods': 'GET,POST,OPTIONS'
    }
    
    try:
        # Handle OPTIONS request for CORS
        if event.get('httpMethod') == 'OPTIONS':
            return {
                'statusCode': 200,
                'headers': headers,
                'body': json.dumps({'message': 'CORS preflight'})
            }
        
        # Parse input
        if 'body' in event:
            # API Gateway request
            body = json.loads(event['body']) if isinstance(event['body'], str) else event['body']
            bucket = body.get('bucket', 'image-analyzer-workshop-1751722329')
            image_data = body.get('image_data')
            
            if not image_data:
                return {
                    'statusCode': 400,
                    'headers': headers,
                    'body': json.dumps({'error': 'Missing image_data parameter'})
                }
            
            # Generate unique key for the image
            key = f"uploads/{datetime.now().strftime('%Y/%m/%d')}/{str(uuid.uuid4())}.jpg"
            
            # Upload image to S3
            try:
                image_bytes = base64.b64decode(image_data)
                s3.put_object(
                    Bucket=bucket,
                    Key=key,
                    Body=image_bytes,
                    ContentType='image/jpeg'
                )
                print(f"Image uploaded to s3://{bucket}/{key}")
            except Exception as e:
                print(f"Failed to upload image to S3: {str(e)}")
                return {
                    'statusCode': 500,
                    'headers': headers,
                    'body': json.dumps({'error': f'Failed to upload image: {str(e)}'})
                }
                
        elif 'Records' in event:
            # S3 trigger
            bucket = event['Records'][0]['s3']['bucket']['name']
            key = unquote_plus(event['Records'][0]['s3']['object']['key'])
        else:
            # Direct invocation
            bucket = event.get('bucket')
            key = event.get('key')
            
        if not bucket or not key:
            return {
                'statusCode': 400,
                'headers': headers,
                'body': json.dumps({'error': 'Missing bucket or key parameter'})
            }
        
        # Comprehensive image analysis with Rekognition
        print(f"Analyzing image: s3://{bucket}/{key}")
        rekognition_results = comprehensive_rekognition_analysis(bucket, key)
        
        # Get advanced analysis with Bedrock
        bedrock_analysis = analyze_with_bedrock(bucket, key, rekognition_results)
        
        # Combine results
        analysis_result = {
            'image': f's3://{bucket}/{key}',
            'basic_analysis': rekognition_results,
            'advanced_analysis': bedrock_analysis,
            'timestamp': datetime.now().isoformat(),
            'request_id': context.aws_request_id
        }
        
        return {
            'statusCode': 200,
            'headers': headers,
            'body': json.dumps(analysis_result, indent=2)
        }
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return {
            'statusCode': 500,
            'headers': headers,
            'body': json.dumps({'error': f'Error analyzing image: {str(e)}'})
        }

def comprehensive_rekognition_analysis(bucket, key):
    """Ph√¢n t√≠ch to√†n di·ªán v·ªõi Amazon Rekognition"""
    
    results = {}
    
    try:
        # 1. Detect labels (objects, scenes, activities)
        labels_response = rekognition.detect_labels(
            Image={'S3Object': {'Bucket': bucket, 'Name': key}},
            MaxLabels=30,
            MinConfidence=60,
            Features=['GENERAL_LABELS', 'IMAGE_PROPERTIES']
        )
        
        results['labels'] = [
            {
                'name': label['Name'],
                'confidence': round(label['Confidence'], 2),
                'categories': [cat['Name'] for cat in label.get('Categories', [])],
                'instances': len(label.get('Instances', [])),
                'parents': [parent['Name'] for parent in label.get('Parents', [])]
            }
            for label in labels_response['Labels']
        ]
        
        # Extract image properties if available
        if 'ImageProperties' in labels_response:
            image_props = labels_response['ImageProperties']
            results['image_properties'] = {
                'quality': image_props.get('Quality', {}),
                'dominant_colors': [
                    {
                        'color': color.get('SimplifiedColor', 'Unknown'),
                        'hex': color.get('CSSColor', '#000000'),
                        'pixel_percent': round(color.get('PixelPercent', 0), 2)
                    }
                    for color in image_props.get('DominantColors', [])[:5]
                ],
                'foreground': image_props.get('Foreground', {}),
                'background': image_props.get('Background', {})
            }
        
        # 2. Detect faces with comprehensive attributes
        faces_response = rekognition.detect_faces(
            Image={'S3Object': {'Bucket': bucket, 'Name': key}},
            Attributes=['ALL']
        )
        
        results['faces'] = []
        for face in faces_response['FaceDetails']:
            face_analysis = {
                'age_range': face['AgeRange'],
                'gender': {
                    'value': face['Gender']['Value'],
                    'confidence': round(face['Gender']['Confidence'], 2)
                },
                'emotions': [
                    {
                        'type': emotion['Type'],
                        'confidence': round(emotion['Confidence'], 2)
                    }
                    for emotion in sorted(face['Emotions'], key=lambda x: x['Confidence'], reverse=True)[:5]
                ],
                'attributes': {
                    'smile': face.get('Smile', {}),
                    'eyeglasses': face.get('Eyeglasses', {}),
                    'sunglasses': face.get('Sunglasses', {}),
                    'beard': face.get('Beard', {}),
                    'mustache': face.get('Mustache', {}),
                    'eyes_open': face.get('EyesOpen', {}),
                    'mouth_open': face.get('MouthOpen', {})
                },
                'quality': face.get('Quality', {}),
                'pose': {
                    'roll': round(face.get('Pose', {}).get('Roll', 0), 2),
                    'yaw': round(face.get('Pose', {}).get('Yaw', 0), 2),
                    'pitch': round(face.get('Pose', {}).get('Pitch', 0), 2)
                }
            }
            results['faces'].append(face_analysis)
        
        # 3. Detect text with location info
        text_response = rekognition.detect_text(
            Image={'S3Object': {'Bucket': bucket, 'Name': key}}
        )
        
        results['text'] = [
            {
                'text': text['DetectedText'],
                'confidence': round(text['Confidence'], 2),
                'type': text['Type'],
                'id': text.get('Id', 0)
            }
            for text in text_response['TextDetections']
            if text['Type'] == 'LINE' and text['Confidence'] > 70
        ]
        
        # 4. Detect celebrities (if any)
        try:
            celebrities_response = rekognition.recognize_celebrities(
                Image={'S3Object': {'Bucket': bucket, 'Name': key}}
            )
            
            results['celebrities'] = [
                {
                    'name': celeb['Name'],
                    'confidence': round(celeb['MatchConfidence'], 2),
                    'urls': celeb.get('Urls', [])
                }
                for celeb in celebrities_response['CelebrityFaces']
                if celeb['MatchConfidence'] > 80
            ]
        except:
            results['celebrities'] = []
        
        # 5. Detect moderation labels
        try:
            moderation_response = rekognition.detect_moderation_labels(
                Image={'S3Object': {'Bucket': bucket, 'Name': key}},
                MinConfidence=60
            )
            
            results['content_moderation'] = [
                {
                    'name': label['Name'],
                    'confidence': round(label['Confidence'], 2),
                    'parent_name': label.get('ParentName', '')
                }
                for label in moderation_response['ModerationLabels']
            ]
        except:
            results['content_moderation'] = []
        
    except Exception as e:
        results['error'] = f"Rekognition analysis failed: {str(e)}"
        print(f"Rekognition error: {str(e)}")
    
    return results

def analyze_with_bedrock(bucket, key, rekognition_data):
    """Ph√¢n t√≠ch n√¢ng cao v·ªõi Amazon Bedrock"""
    
    try:
        # Create comprehensive prompt
        prompt = create_comprehensive_analysis_prompt(rekognition_data)
        
        # Try different model IDs
        model_ids = [
            'anthropic.claude-3-haiku-20240307-v1:0',
            'anthropic.claude-v2:1',
            'anthropic.claude-v2'
        ]
        
        for model_id in model_ids:
            try:
                print(f"Trying Bedrock model: {model_id}")
                
                if 'claude-3' in model_id:
                    response = bedrock.invoke_model(
                        modelId=model_id,
                        body=json.dumps({
                            'anthropic_version': 'bedrock-2023-05-31',
                            'max_tokens': 1500,
                            'messages': [
                                {
                                    'role': 'user',
                                    'content': prompt
                                }
                            ]
                        })
                    )
                    
                    response_body = json.loads(response['body'].read())
                    analysis = response_body['content'][0]['text']
                else:
                    response = bedrock.invoke_model(
                        modelId=model_id,
                        body=json.dumps({
                            'prompt': f"\n\nHuman: {prompt}\n\nAssistant:",
                            'max_tokens_to_sample': 1500,
                            'temperature': 0.7,
                            'top_p': 1,
                        })
                    )
                    
                    response_body = json.loads(response['body'].read())
                    analysis = response_body['completion']
                
                return {
                    'artistic_analysis': analysis.strip(),
                    'model_used': model_id,
                    'analysis_type': 'ai_generated'
                }
                
            except Exception as model_error:
                print(f"Model {model_id} failed: {str(model_error)}")
                continue
        
        raise Exception("All Bedrock models failed")
        
    except Exception as e:
        print(f"Bedrock error: {str(e)}")
        return {
            'artistic_analysis': generate_comprehensive_fallback_analysis(rekognition_data),
            'model_used': 'Comprehensive Fallback Analysis',
            'analysis_type': 'rule_based',
            'note': 'Bedrock kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng ph√¢n t√≠ch d·ª± ph√≤ng chi ti·∫øt'
        }

def create_comprehensive_analysis_prompt(rekognition_data):
    """T·∫°o prompt chi ti·∫øt cho Bedrock"""
    
    labels = rekognition_data.get('labels', [])
    faces = rekognition_data.get('faces', [])
    text = rekognition_data.get('text', [])
    colors = rekognition_data.get('image_properties', {}).get('dominant_colors', [])
    celebrities = rekognition_data.get('celebrities', [])
    
    # Categorize labels
    people_labels = [l['name'] for l in labels if any(cat in ['People', 'Person'] for cat in l.get('categories', []))]
    object_labels = [l['name'] for l in labels if any(cat in ['Objects', 'Vehicles', 'Electronics'] for cat in l.get('categories', []))]
    scene_labels = [l['name'] for l in labels if any(cat in ['Outdoors', 'Indoors', 'Nature'] for cat in l.get('categories', []))]
    activity_labels = [l['name'] for l in labels if any(cat in ['Activities', 'Sports', 'Hobbies'] for cat in l.get('categories', []))]
    
    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch ngh·ªá thu·∫≠t v√† nhi·∫øp ·∫£nh. H√£y ph√¢n t√≠ch b·ª©c ·∫£nh d·ª±a tr√™n th√¥ng tin chi ti·∫øt sau:

    üé® TH√îNG TIN H√åNH ·∫¢NH:
    - ƒê·ªëi t∆∞·ª£ng ch√≠nh: {', '.join(people_labels[:5]) if people_labels else 'Kh√¥ng c√≥ ng∆∞·ªùi'}
    - V·∫≠t th·ªÉ: {', '.join(object_labels[:5]) if object_labels else 'Kh√¥ng r√µ'}
    - B·ªëi c·∫£nh: {', '.join(scene_labels[:3]) if scene_labels else 'Kh√¥ng x√°c ƒë·ªãnh'}
    - Ho·∫°t ƒë·ªông: {', '.join(activity_labels[:3]) if activity_labels else 'Kh√¥ng c√≥'}
    - M√†u s·∫Øc ch·ªß ƒë·∫°o: {', '.join([c['color'] for c in colors[:3]]) if colors else 'Kh√¥ng x√°c ƒë·ªãnh'}
    - VƒÉn b·∫£n: {', '.join([t['text'] for t in text[:3]]) if text else 'Kh√¥ng c√≥'}
    - Ng∆∞·ªùi n·ªïi ti·∫øng: {', '.join([c['name'] for c in celebrities]) if celebrities else 'Kh√¥ng c√≥'}

    üë• TH√îNG TIN KHU√îN M·∫∂T ({len(faces)} ng∆∞·ªùi):
    """
    
    for i, face in enumerate(faces[:2]):  # Ch·ªâ ph√¢n t√≠ch 2 khu√¥n m·∫∑t ƒë·∫ßu
        emotions = ', '.join([f"{e['type']}({e['confidence']:.1f}%)" for e in face['emotions'][:3]])
        prompt += f"""
    - Ng∆∞·ªùi {i+1}: {face['gender']['value']}, {face['age_range']['Low']}-{face['age_range']['High']} tu·ªïi
      C·∫£m x√∫c: {emotions}
      ƒê·∫∑c ƒëi·ªÉm: {'C√≥ n·ª• c∆∞·ªùi' if face['attributes']['smile'].get('Value') else 'Kh√¥ng c∆∞·ªùi'}, {'ƒêeo k√≠nh' if face['attributes']['eyeglasses'].get('Value') else 'Kh√¥ng k√≠nh'}
        """
    
    prompt += f"""

    üìù Y√äU C·∫¶U PH√ÇN T√çCH:
    H√£y vi·∫øt m·ªôt ƒëo·∫°n ph√¢n t√≠ch 4-6 c√¢u bao g·ªìm:
    1. Composition v√† b·ªë c·ª•c t·ªïng th·ªÉ
    2. M√†u s·∫Øc v√† √°nh s√°ng
    3. C·∫£m x√∫c v√† t√¢m tr·∫°ng ƒë∆∞·ª£c truy·ªÅn t·∫£i
    4. K·ªπ thu·∫≠t nhi·∫øp ·∫£nh (g√≥c ch·ª•p, ƒë·ªô s√¢u tr∆∞·ªùng ·∫£nh)
    5. Gi√° tr·ªã ngh·ªá thu·∫≠t v√† th·∫©m m·ªπ
    6. G·ª£i √Ω c·∫£i thi·ªán c·ª• th·ªÉ

    Vi·∫øt b·∫±ng ti·∫øng Vi·ªát, phong c√°ch chuy√™n nghi·ªáp nh∆∞ng d·ªÖ hi·ªÉu.
    """
    
    return prompt

def generate_comprehensive_fallback_analysis(rekognition_data):
    """T·∫°o ph√¢n t√≠ch d·ª± ph√≤ng chi ti·∫øt"""
    
    labels = rekognition_data.get('labels', [])
    faces = rekognition_data.get('faces', [])
    text = rekognition_data.get('text', [])
    colors = rekognition_data.get('image_properties', {}).get('dominant_colors', [])
    
    analysis_parts = []
    
    # Ph√¢n t√≠ch composition
    if labels:
        main_subjects = [label['name'] for label in labels[:3]]
        analysis_parts.append(f"B·ª©c ·∫£nh c√≥ composition t·∫≠p trung v√†o {', '.join(main_subjects).lower()}")
        
        # Ph√¢n t√≠ch theo category
        categories = {}
        for label in labels[:10]:
            for cat in label.get('categories', []):
                categories[cat] = categories.get(cat, 0) + 1
        
        dominant_category = max(categories.items(), key=lambda x: x[1])[0] if categories else None
        if dominant_category:
            analysis_parts.append(f"v·ªõi ch·ªß ƒë·ªÅ ch√≠nh thu·ªôc nh√≥m {dominant_category}")
    
    # Ph√¢n t√≠ch m√†u s·∫Øc
    if colors:
        color_names = [color['color'] for color in colors[:3]]
        analysis_parts.append(f"T√¥ng m√†u ch·ªß ƒë·∫°o l√† {', '.join(color_names).lower()}, t·∫°o c·∫£m gi√°c h√†i h√≤a v√† c√¢n b·∫±ng")
    
    # Ph√¢n t√≠ch khu√¥n m·∫∑t
    if faces:
        face_count = len(faces)
        if face_count == 1:
            face = faces[0]
            age_range = f"{face['age_range']['Low']}-{face['age_range']['High']}"
            top_emotion = face['emotions'][0]['type'] if face['emotions'] else 'CALM'
            analysis_parts.append(f"Ch√¢n dung c·ªßa m·ªôt {face['gender']['value'].lower()} kho·∫£ng {age_range} tu·ªïi v·ªõi c·∫£m x√∫c {top_emotion.lower()}")
        else:
            analysis_parts.append(f"·∫¢nh nh√≥m v·ªõi {face_count} ng∆∞·ªùi, th·ªÉ hi·ªán s·ª± t∆∞∆°ng t√°c x√£ h·ªôi")
    
    # Ph√¢n t√≠ch text
    if text:
        analysis_parts.append(f"C√≥ y·∫øu t·ªë vƒÉn b·∫£n '{text[0]['text']}' l√†m tƒÉng t√≠nh th√¥ng tin")
    
    # ƒê√°nh gi√° k·ªπ thu·∫≠t
    quality_assessment = []
    if faces:
        avg_quality = sum([face.get('quality', {}).get('Brightness', 50) for face in faces]) / len(faces)
        if avg_quality > 70:
            quality_assessment.append("ch·∫•t l∆∞·ª£ng √°nh s√°ng t·ªët")
        elif avg_quality < 30:
            quality_assessment.append("√°nh s√°ng c·∫ßn c·∫£i thi·ªán")
    
    if quality_assessment:
        analysis_parts.append(f"V·ªÅ m·∫∑t k·ªπ thu·∫≠t, ·∫£nh c√≥ {', '.join(quality_assessment)}")
    
    # G·ª£i √Ω c·∫£i thi·ªán
    suggestions = []
    if not faces and not labels:
        suggestions.append("tƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n")
    if len(colors) < 2:
        suggestions.append("c√¢n b·∫±ng m√†u s·∫Øc")
    if faces and any(face.get('quality', {}).get('Brightness', 50) < 40 for face in faces):
        suggestions.append("c·∫£i thi·ªán √°nh s√°ng")
    
    if suggestions:
        analysis_parts.append(f"C√≥ th·ªÉ c·∫£i thi·ªán b·∫±ng c√°ch {', '.join(suggestions)}")
    
    # K·∫øt h·ª£p th√†nh ƒëo·∫°n vƒÉn
    if analysis_parts:
        return '. '.join(analysis_parts) + '.'
    else:
        return "ƒê√¢y l√† m·ªôt b·ª©c ·∫£nh c√≥ ch·∫•t l∆∞·ª£ng t·ªët v·ªõi composition c√¢n ƒë·ªëi v√† m√†u s·∫Øc h√†i h√≤a. K·ªπ thu·∫≠t ch·ª•p ·ªïn ƒë·ªãnh, th·ªÉ hi·ªán ƒë∆∞·ª£c √Ω t∆∞·ªüng c·ªßa t√°c gi·∫£."
